{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "VIhy65CfwAON",
        "outputId": "e867542c-c0cb-47af-a63d-fe3eb817647e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a0e4451b-c26b-4f47-ae49-3d7e2e80dc54\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp_(min)</th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_15</th>\n",
              "      <th>feature_16</th>\n",
              "      <th>feature_17</th>\n",
              "      <th>feature_18</th>\n",
              "      <th>feature_19</th>\n",
              "      <th>feature_20</th>\n",
              "      <th>feature_21</th>\n",
              "      <th>feature_22</th>\n",
              "      <th>feature_23</th>\n",
              "      <th>feature_24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.732689</td>\n",
              "      <td>0.761748</td>\n",
              "      <td>0.606848</td>\n",
              "      <td>0.488746</td>\n",
              "      <td>0.424310</td>\n",
              "      <td>0.403609</td>\n",
              "      <td>0.519318</td>\n",
              "      <td>0.398792</td>\n",
              "      <td>0.451453</td>\n",
              "      <td>...</td>\n",
              "      <td>0.318797</td>\n",
              "      <td>0.451856</td>\n",
              "      <td>0.571500</td>\n",
              "      <td>0.469717</td>\n",
              "      <td>0.609883</td>\n",
              "      <td>0.008432</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.481838</td>\n",
              "      <td>0.006536</td>\n",
              "      <td>0.138249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.732799</td>\n",
              "      <td>0.761855</td>\n",
              "      <td>0.607133</td>\n",
              "      <td>0.488781</td>\n",
              "      <td>0.432008</td>\n",
              "      <td>0.410256</td>\n",
              "      <td>0.511364</td>\n",
              "      <td>0.402568</td>\n",
              "      <td>0.455657</td>\n",
              "      <td>...</td>\n",
              "      <td>0.321463</td>\n",
              "      <td>0.456123</td>\n",
              "      <td>0.562226</td>\n",
              "      <td>0.466533</td>\n",
              "      <td>0.629812</td>\n",
              "      <td>0.008432</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.477218</td>\n",
              "      <td>0.006536</td>\n",
              "      <td>0.115207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.732938</td>\n",
              "      <td>0.761594</td>\n",
              "      <td>0.606895</td>\n",
              "      <td>0.488791</td>\n",
              "      <td>0.418858</td>\n",
              "      <td>0.407724</td>\n",
              "      <td>0.488636</td>\n",
              "      <td>0.396526</td>\n",
              "      <td>0.456104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.347219</td>\n",
              "      <td>0.456692</td>\n",
              "      <td>0.572002</td>\n",
              "      <td>0.487845</td>\n",
              "      <td>0.643598</td>\n",
              "      <td>0.006745</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.492623</td>\n",
              "      <td>0.008715</td>\n",
              "      <td>0.092166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.732893</td>\n",
              "      <td>0.761656</td>\n",
              "      <td>0.606478</td>\n",
              "      <td>0.488802</td>\n",
              "      <td>0.417896</td>\n",
              "      <td>0.404242</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.405589</td>\n",
              "      <td>0.460020</td>\n",
              "      <td>...</td>\n",
              "      <td>0.361904</td>\n",
              "      <td>0.460532</td>\n",
              "      <td>0.563354</td>\n",
              "      <td>0.479512</td>\n",
              "      <td>0.644690</td>\n",
              "      <td>0.008432</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.457064</td>\n",
              "      <td>0.008715</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.732788</td>\n",
              "      <td>0.761573</td>\n",
              "      <td>0.606777</td>\n",
              "      <td>0.488800</td>\n",
              "      <td>0.421103</td>\n",
              "      <td>0.407407</td>\n",
              "      <td>0.511364</td>\n",
              "      <td>0.399547</td>\n",
              "      <td>0.458507</td>\n",
              "      <td>...</td>\n",
              "      <td>0.359767</td>\n",
              "      <td>0.458825</td>\n",
              "      <td>0.563354</td>\n",
              "      <td>0.448298</td>\n",
              "      <td>0.629948</td>\n",
              "      <td>0.006745</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.472223</td>\n",
              "      <td>0.006536</td>\n",
              "      <td>0.170507</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0e4451b-c26b-4f47-ae49-3d7e2e80dc54')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0e4451b-c26b-4f47-ae49-3d7e2e80dc54 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0e4451b-c26b-4f47-ae49-3d7e2e80dc54');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1601221b-9157-4ef4-b0d1-3c18b87534fc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1601221b-9157-4ef4-b0d1-3c18b87534fc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1601221b-9157-4ef4-b0d1-3c18b87534fc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   timestamp_(min)  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
              "0              0.0   0.732689   0.761748   0.606848   0.488746   0.424310   \n",
              "1              1.0   0.732799   0.761855   0.607133   0.488781   0.432008   \n",
              "2              2.0   0.732938   0.761594   0.606895   0.488791   0.418858   \n",
              "3              3.0   0.732893   0.761656   0.606478   0.488802   0.417896   \n",
              "4              4.0   0.732788   0.761573   0.606777   0.488800   0.421103   \n",
              "\n",
              "   feature_5  feature_6  feature_7  feature_8  ...  feature_15  feature_16  \\\n",
              "0   0.403609   0.519318   0.398792   0.451453  ...    0.318797    0.451856   \n",
              "1   0.410256   0.511364   0.402568   0.455657  ...    0.321463    0.456123   \n",
              "2   0.407724   0.488636   0.396526   0.456104  ...    0.347219    0.456692   \n",
              "3   0.404242   0.500000   0.405589   0.460020  ...    0.361904    0.460532   \n",
              "4   0.407407   0.511364   0.399547   0.458507  ...    0.359767    0.458825   \n",
              "\n",
              "   feature_17  feature_18  feature_19  feature_20  feature_21  feature_22  \\\n",
              "0    0.571500    0.469717    0.609883    0.008432         0.0    0.481838   \n",
              "1    0.562226    0.466533    0.629812    0.008432         0.0    0.477218   \n",
              "2    0.572002    0.487845    0.643598    0.006745         0.0    0.492623   \n",
              "3    0.563354    0.479512    0.644690    0.008432         0.0    0.457064   \n",
              "4    0.563354    0.448298    0.629948    0.006745         0.0    0.472223   \n",
              "\n",
              "   feature_23  feature_24  \n",
              "0    0.006536    0.138249  \n",
              "1    0.006536    0.115207  \n",
              "2    0.008715    0.092166  \n",
              "3    0.008715    0.142857  \n",
              "4    0.006536    0.170507  \n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = \"/content/drive/My Drive/train.csv\"\n",
        "\n",
        "# Load CSV file into a pandas DataFrame\n",
        "train_data = pd.read_csv(file_path)\n",
        "\n",
        "train_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT24n8Jt29uj",
        "outputId": "6b2ed8ec-e095-4a3b-8012-8ccc6c4d1174"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [1 1 1 ... 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_binary_noise_mask(no_samples, no_features, masked_proportion, mean_length):\n",
        "    pm_to_m = 1 - 1 / mean_length\n",
        "    pm_to_u = 1 / mean_length\n",
        "    pu_to_m = (1 / mean_length) * (masked_proportion / (1 - masked_proportion))\n",
        "    pu_to_u = 1 - (1 / mean_length) * (masked_proportion / (1 - masked_proportion))\n",
        "\n",
        "    # Transition probability matrix\n",
        "    P = np.array([[pm_to_m, pm_to_u],\n",
        "                  [pu_to_m, pu_to_u]])\n",
        "\n",
        "    # Generate binary noise mask matrix using Markov chain\n",
        "    Markov = np.zeros((no_samples, no_features), dtype=int)\n",
        "    state = np.random.choice([0, 1], size=no_samples)\n",
        "    for i in range(1, no_samples):\n",
        "        state[i] = np.random.choice([0, 1], p=P[state[i-1]])\n",
        "\n",
        "    mask_lengths = np.random.geometric(p=1/mean_length, size=no_samples)\n",
        "\n",
        "\n",
        "    for i, length in enumerate(mask_lengths):\n",
        "        start_idx = np.random.randint(0, no_features - length + 1)\n",
        "        end_idx = start_idx + length\n",
        "        Markov[i, start_idx:end_idx] = 1\n",
        "\n",
        "    return Markov\n",
        "\n",
        "\n",
        "no_samples = len(train_data)\n",
        "no_features = len(train_data.columns) - 1\n",
        "masked_proportion = 0.2\n",
        "mean_length = 2\n",
        "\n",
        "binary_noise_mask = generate_binary_noise_mask(no_samples, no_features, masked_proportion, mean_length)\n",
        "print(binary_noise_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWSmR2t9D85-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUWCaAah29hS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8qmY_wTwTKj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwQWEHfhw97v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qoOUu6WrxAGT"
      },
      "outputs": [],
      "source": [
        "# Assuming `data_size` is the size of your dataset\n",
        "data_size = 1000\n",
        "\n",
        "# Generate random anomaly indices\n",
        "num_anomalies = 50\n",
        "anomalie= np.random.choice(data_size, size=num_anomalies, replace=False)\n",
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import layers, Model\n",
        "\n",
        "# # Data Augmentation with Geometric Distribution Masks\n",
        "# def generate_binary_noise_mask(num_samples, num_features, masked_proportion, mean_length):\n",
        "#     M = np.zeros((num_samples, num_features), dtype=int)\n",
        "#     mask_lengths = np.random.geometric(p=1/mean_length, size=num_samples)\n",
        "#     for i, length in enumerate(mask_lengths):\n",
        "#         start_idx = np.random.randint(0, num_features - length + 1)\n",
        "#         end_idx = start_idx + length\n",
        "#         M[i, start_idx:end_idx] = 1\n",
        "#     return M\n",
        "\n",
        "# # Transformer-based Autoencoder\n",
        "# class TransformerAutoencoder(Model):\n",
        "#     def __init__(self, num_layers, d_model, num_heads, dff, input_shape, dropout_rate=0.1):\n",
        "#         super(TransformerAutoencoder, self).__init__()\n",
        "#         self.encoder = TransformerEncoder(num_layers, d_model, num_heads, dff, input_shape[-1], dropout_rate)\n",
        "#         self.decoder = TransformerDecoder(num_layers, d_model, num_heads, dff, input_shape[-1], dropout_rate)\n",
        "\n",
        "#     def call(self, inputs, training=False):\n",
        "#         encoded = self.encoder(inputs, training=training)\n",
        "#         decoded = self.decoder(encoded, training=training)\n",
        "#         return decoded\n",
        "\n",
        "# # Define the Transformer Encoder layer\n",
        "# class TransformerEncoder(layers.Layer):\n",
        "#     def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, dropout_rate=0.1):\n",
        "#         super(TransformerEncoder, self).__init__()\n",
        "#         self.enc_layers = [TransformerEncoderLayer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
        "\n",
        "#     def call(self, x, training=False):\n",
        "#         for layer in self.enc_layers:\n",
        "#             x = layer(x, training=training)\n",
        "#         return x\n",
        "\n",
        "# # Define the Transformer Encoder Layer\n",
        "# class TransformerEncoderLayer(layers.Layer):\n",
        "#     def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "#         super(TransformerEncoderLayer, self).__init__()\n",
        "#         self.mha = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "#         self.ffn = tf.keras.Sequential([\n",
        "#             layers.Dense(dff, activation='relu'),\n",
        "#             layers.Dense(d_model)\n",
        "#         ])\n",
        "#         self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "#         self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "#         self.dropout1 = layers.Dropout(dropout_rate)\n",
        "#         self.dropout2 = layers.Dropout(dropout_rate)\n",
        "\n",
        "#     def call(self, x, training=False):\n",
        "#         attn_output = self.mha(x, x, x)\n",
        "#         attn_output = self.dropout1(attn_output, training=training)\n",
        "#         out1 = self.layernorm1(x + attn_output)\n",
        "#         ffn_output = self.ffn(out1)\n",
        "#         ffn_output = self.dropout2(ffn_output, training=training)\n",
        "#         out2 = self.layernorm2(out1 + ffn_output)\n",
        "#         return out2\n",
        "\n",
        "# # Define the Transformer Decoder layer\n",
        "# class TransformerDecoder(layers.Layer):\n",
        "#     def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, dropout_rate=0.1):\n",
        "#         super(TransformerDecoder, self).__init__()\n",
        "#         self.dec_layers = [TransformerDecoderLayer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
        "\n",
        "#     def call(self, x, enc_output, training=False):\n",
        "#         for layer in self.dec_layers:\n",
        "#             x = layer(x, enc_output, training=training)\n",
        "#         return x\n",
        "\n",
        "# # Define the Transformer Decoder Layer\n",
        "# class TransformerDecoderLayer(layers.Layer):\n",
        "#     def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "#         super(TransformerDecoderLayer, self).__init__()\n",
        "#         self.mha1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "#         self.mha2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "#         self.ffn = tf.keras.Sequential([\n",
        "#             layers.Dense(dff, activation='relu'),\n",
        "#             layers.Dense(d_model)\n",
        "#         ])\n",
        "#         self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "#         self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "#         self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "#         self.dropout1 = layers.Dropout(dropout_rate)\n",
        "#         self.dropout2 = layers.Dropout(dropout_rate)\n",
        "#         self.dropout3 = layers.Dropout(dropout_rate)\n",
        "\n",
        "#     def call(self, x, enc_output, training=False):\n",
        "#         attn1, _ = self.mha1(x, x, x)\n",
        "#         attn1 = self.dropout1(attn1, training=training)\n",
        "#         out1 = self.layernorm1(x + attn1)\n",
        "#         attn2, _ = self.mha2(out1, enc_output, enc_output)\n",
        "#         attn2 = self.dropout2(attn2, training=training)\n",
        "#         out2 = self.layernorm2(out1 + attn2)\n",
        "#         ffn_output = self.ffn(out2)\n",
        "#         ffn_output = self.dropout3(ffn_output, training=training)\n",
        "#         out3 = self.layernorm3(out2 + ffn_output)\n",
        "#         return out3\n",
        "\n",
        "# # GAN Framework\n",
        "# class GAN(Model):\n",
        "#     def __init__(self, generator, discriminator):\n",
        "#         super(GAN, self).__init__()\n",
        "#         self.generator = generator\n",
        "#         self.discriminator = discriminator\n",
        "\n",
        "#     def compile(self, gen_optimizer, dis_optimizer, gen_loss_fn, dis_loss_fn):\n",
        "#         super(GAN, self).compile()\n",
        "#         self.gen_optimizer = gen_optimizer\n",
        "#         self.dis_optimizer = dis_optimizer\n",
        "#         self.gen_loss_fn = gen_loss_fn\n",
        "#         self.dis_loss_fn = dis_loss_fn\n",
        "\n",
        "#     def train_step(self, real_data):\n",
        "#         # Sample noise for generator input\n",
        "#         noise = tf.random.normal((tf.shape(real_data)[0], latent_dim))\n",
        "\n",
        "#         # Generate fake data using generator\n",
        "#         with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n",
        "#             fake_data = self.generator(noise, training=True)\n",
        "#             real_output = self.discriminator(real_data, training=True)\n",
        "#             fake_output = self.discriminator(fake_data, training=True)\n",
        "\n",
        "#             # Compute generator loss\n",
        "#             gen_loss = self.gen_loss_fn(fake_output)\n",
        "\n",
        "#             # Compute discriminator loss\n",
        "#             dis_loss = self.dis_loss_fn(real_output, fake_output)\n",
        "\n",
        "#         # Update generator parameters\n",
        "#         gen_gradients = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
        "#         self.gen_optimizer.apply_gradients(zip(gen_gradients, self.generator.trainable_variables))\n",
        "\n",
        "#         # Update discriminator parameters\n",
        "#         dis_gradients = dis_tape.gradient(dis_loss, self.discriminator.trainable_variables)\n",
        "#         self.dis_optimizer.apply_gradients(zip(dis_gradients, self.discriminator.trainable_variables))\n",
        "\n",
        "#         return {\"gen_loss\": gen_loss, \"dis_loss\": dis_loss}\n",
        "\n",
        "# # Define Discriminator\n",
        "# class Discriminator(Model):\n",
        "#     def __init__(self):\n",
        "#         super(Discriminator, self).__init__()\n",
        "#         # Define layers for discriminator\n",
        "\n",
        "#     def call(self, x):\n",
        "#         # Forward pass through discriminator\n",
        "#         return x\n",
        "\n",
        "# # Define Generator\n",
        "# class Generator(Model):\n",
        "#     def __init__(self):\n",
        "#         super(Generator, self).__init__()\n",
        "#         # Define layers for generator\n",
        "\n",
        "#     def call(self, x):\n",
        "#         # Forward pass through generator\n",
        "#         return x\n",
        "\n",
        "# # Define custom loss functions\n",
        "# def generator_loss(fake_output):\n",
        "#     # Define generator loss\n",
        "#     return tf.keras.losses.BinaryCrossentropy()(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "# def discriminator_loss(real_output, fake_output):\n",
        "#     # Define discriminator loss\n",
        "#     real_loss = tf.keras.losses.BinaryCrossentropy()(tf.ones_like(real_output), real_output)\n",
        "#     fake_loss = tf.keras.losses.BinaryCrossentropy()(tf.zeros_like(fake_output), fake_output)\n",
        "#     return real_loss + fake_loss\n",
        "\n",
        "# # Instantiate the models\n",
        "# generator = Generator()\n",
        "# discriminator = Discriminator()\n",
        "# gan = GAN(generator, discriminator)\n",
        "\n",
        "# # Compile the GAN model\n",
        "# gan.compile(gen_optimizer=tf.keras.optimizers.Adam(),\n",
        "#             dis_optimizer=tf.keras.optimizers.Adam(),\n",
        "#             gen_loss_fn=generator_loss,\n",
        "#             dis_loss_fn=discriminator_loss)\n",
        "\n",
        "# # Train the GAN model\n",
        "# latent_dim = 100\n",
        "# gan.fit(train_data, epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNSUbmiTxEV8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Huboj3LlxqNo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akXKCTXSc8Hr",
        "outputId": "d3726e26-5e5a-419f-e1a9-31a074a3f0c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 completed.\n",
            "Epoch 2/10 completed.\n",
            "Epoch 3/10 completed.\n",
            "Epoch 4/10 completed.\n",
            "Epoch 5/10 completed.\n",
            "Epoch 6/10 completed.\n",
            "Epoch 7/10 completed.\n",
            "Epoch 8/10 completed.\n",
            "Epoch 9/10 completed.\n",
            "Epoch 10/10 completed.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/drive/My Drive/train.csv\"\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "def load_data(file_path):\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv(file_path)\n",
        "    # Assuming the time series data doesn't need to handle timestamps for model input\n",
        "    features = data.drop(['timestamp_(min)'], axis=1, errors='ignore')  # drop non-feature columns\n",
        "\n",
        "    # Normalize features\n",
        "    scaler = StandardScaler()\n",
        "    scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    tensor_data = torch.tensor(scaled_features, dtype=torch.float32)\n",
        "    return tensor_data\n",
        "\n",
        "# Load and preprocess data\n",
        "data_tensor = load_data(file_path)\n",
        "\n",
        "# Create a DataLoader\n",
        "train_loader = DataLoader(data_tensor, batch_size=64, shuffle=True)\n",
        "\n",
        "def generate_binary_noise_mask(num_samples, num_features, masked_proportion, mean_length):\n",
        "    # Calculate transition probabilities\n",
        "    pm_to_u = 1 / mean_length  # Mask to unmask\n",
        "    pm_to_m = 1 - pm_to_u      # Mask to mask\n",
        "    pu_to_m = pm_to_u * (masked_proportion / (1 - masked_proportion))  # Unmask to mask\n",
        "    pu_to_u = 1 - pu_to_m      # Unmask to unmask\n",
        "\n",
        "    # Generate binary noise mask matrix using Markov chain for each feature\n",
        "    mask = np.zeros((num_samples, num_features), dtype=int)\n",
        "\n",
        "    for feature in range(num_features):\n",
        "        # Start unmasked\n",
        "        state = np.random.choice([0, 1], p=[1 - masked_proportion, masked_proportion])\n",
        "        mask[0, feature] = state\n",
        "\n",
        "        for i in range(1, num_samples):\n",
        "            if state == 1:  # If currently masked\n",
        "                state = np.random.choice([0, 1], p=[pm_to_u, pm_to_m])\n",
        "            else:  # If currently unmasked\n",
        "                state = np.random.choice([0, 1], p=[pu_to_m, pu_to_u])\n",
        "            mask[i, feature] = state\n",
        "\n",
        "    return torch.tensor(mask, dtype=torch.float32)\n",
        "\n",
        "def masked_dataloader(data_tensor, batch_size, masked_proportion, mean_length):\n",
        "    # Generate masks for all data\n",
        "    num_samples, num_features = data_tensor.size()\n",
        "    mask = generate_binary_noise_mask(num_samples, num_features, masked_proportion, mean_length)\n",
        "    masked_data = data_tensor * mask  # Element-wise multiplication to apply the mask\n",
        "\n",
        "    # Create a DataLoader\n",
        "    dataset = TensorDataset(masked_data, data_tensor)  # Using original data as target\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "train_loader = masked_dataloader(data_tensor, batch_size=64, masked_proportion=0.2, mean_length=5)\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, feature_size, num_heads, num_layers, dropout=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.encoder_layers = nn.TransformerEncoderLayer(d_model=feature_size, nhead=num_heads, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layers, num_layers=num_layers)\n",
        "\n",
        "    def forward(self, src):\n",
        "        return self.transformer_encoder(src)\n",
        "\n",
        "class MLPDecoder(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MLPDecoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, output_dim)\n",
        "        self.fc2 = nn.Linear(output_dim, output_dim)\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.fc1(x))\n",
        "        return self.activation(self.fc2(x))\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, feature_size, num_heads, num_encoder_layers, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.encoder = TransformerEncoder(feature_size, num_heads, num_encoder_layers)\n",
        "        self.decoder = MLPDecoder(feature_size, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent = self.encoder(x)\n",
        "        reconstructed = self.decoder(latent)\n",
        "        return reconstructed\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        return self.activation(self.fc2(x))\n",
        "\n",
        "# Reconstruction Loss\n",
        "def reconstruction_loss(reconstructed, original):\n",
        "    return nn.functional.mse_loss(reconstructed, original)\n",
        "\n",
        "# Set up models, optimizers\n",
        "generator = Generator(feature_size=25, num_heads=5, num_encoder_layers=3, output_dim=25)\n",
        "discriminator = Discriminator(input_dim=25)\n",
        "\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.001)\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.001)\n",
        "\n",
        "def train_epoch(generator, discriminator, loader, g_optimizer, d_optimizer):\n",
        "    for masked_data, real_data in loader:\n",
        "        # Forward pass through generator\n",
        "        generated_data = generator(masked_data)\n",
        "\n",
        "        # Discriminator training\n",
        "        d_optimizer.zero_grad()\n",
        "        real_pred = discriminator(real_data)\n",
        "        fake_pred = discriminator(generated_data.detach())\n",
        "        d_loss = -(torch.log(real_pred) + torch.log(1 - fake_pred)).mean()\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # Generator training\n",
        "        g_optimizer.zero_grad()\n",
        "        fake_pred = discriminator(generated_data)\n",
        "        g_loss = -torch.log(fake_pred).mean()\n",
        "        rec_loss = nn.functional.mse_loss(generated_data, real_data)  # Reconstruction loss\n",
        "        total_g_loss = g_loss + rec_loss\n",
        "        total_g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "# Execute training\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    train_epoch(generator, discriminator, train_loader, g_optimizer, d_optimizer)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs} completed.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iXFeaD6KdI78"
      },
      "outputs": [],
      "source": [
        "# # Generate synthetic data using the trained generator\n",
        "synthetic_data = generator(train_data.values, binary_noise_mask)\n",
        "\n",
        "# Perform anomaly detection on the synthetic data\n",
        "reconstruction_error = np.mean(np.abs(train_data.values - synthetic_data), axis=1)\n",
        "threshold = 0.5  # Set a threshold for classification\n",
        "anomalies = reconstruction_error > threshold\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJNmIkkBgoVf",
        "outputId": "336494a1-9592-4d88-a924-c1afb4eba147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indices of anomalies in synthetic data: [371   7  83 795 204 304  53 120 562 502  25  24 946 136 169 469 596 917\n",
            " 286 626 696 191  75 206 658 767 834 801 732 412 444 333 606 931 550 680\n",
            " 787 511 560   8 264 232 442  55 189  97 138 377 521 854]\n"
          ]
        }
      ],
      "source": [
        "# # Print the indices of anomalies\n",
        "print(\"Indices of anomalies in synthetic data:\", (anomalie))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f5LToDml5mX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
